模型剪枝、蒸馏与优化：从 BERT 到轻量学生模型

适用范围
- 将 `bert-base-chinese` 压缩为移动端学生模型，保持任务精度，降低延迟与包体。

步骤一：任务与数据
- 明确任务（分类/序列标注/匹配），统一输入长度与预处理（WordPiece）。
- 划分训练/验证/测试，建立统一评估脚本与指标（F1/Acc）。

步骤二：结构化剪枝
- 剪枝类型：注意力头剪枝、层剪枝、FFN 宽度裁剪。
- 建议：先做注意力头剪枝（依据头重要性/敏感性分析），再评估层剪枝对精度的影响。
```python
from transformers import BertForSequenceClassification

teacher = BertForSequenceClassification.from_pretrained("bert-base-chinese", num_labels=NUM_LABELS)

# 按层定义需删除的注意力头集合
prune_dict = {0: {0, 3, 7}, 1: {2, 5}, 2: {1}}
# 直接对 BERT 进行头剪枝（HF 模型支持）
teacher.bert.prune_heads(prune_dict)
```

步骤三：知识蒸馏（Teacher → Student）
- 学生结构：TinyBERT/MobileBERT 风格（更浅/更窄/瓶颈结构）。
- 损失：任务监督损失 + Logits KL 散度 + 中间层对齐（可选）。
```python
import torch, torch.nn.functional as F
from transformers import BertForSequenceClassification, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")
teacher = BertForSequenceClassification.from_pretrained("bert-base-chinese", num_labels=NUM_LABELS).eval()
student = BertForSequenceClassification.from_pretrained("huawei-noah/TinyBERT_General_4L_312D", num_labels=NUM_LABELS)

def distill_step(batch):
    with torch.no_grad():
        t_out = teacher(**batch)
    s_out = student(**batch)
    # 任务监督
    ce = F.cross_entropy(s_out.logits, batch["labels"]) 
    # 蒸馏：Logits 温度平滑
    T = 2.0
    kl = F.kl_div(
        F.log_softmax(s_out.logits / T, dim=-1),
        F.softmax(t_out.logits / T, dim=-1),
        reduction="batchmean"
    ) * (T * T)
    loss = 0.5 * ce + 0.5 * kl
    loss.backward()
    return loss.item()
```

步骤四：权重/结构优化
- 动态量化（PTQ）：线性层 INT8；激活保持 FP16/FP32 以降低风险。
- 非结构化剪枝：对 `Linear` 层做 L1 剪枝与稀疏化（推理框架需支持稀疏算子）。
```python
import torch
from torch.quantization import quantize_dynamic
import torch.nn.utils.prune as prune

# 动态量化（线性层）
student_q = quantize_dynamic(student, {torch.nn.Linear}, dtype=torch.qint8)

# 非结构化剪枝示例（谨慎使用）
for name, module in student.named_modules():
    if isinstance(module, torch.nn.Linear):
        prune.l1_unstructured(module, name='weight', amount=0.3)
        prune.remove(module, 'weight')  # 将稀疏化合并回权重
```

步骤五：评估与回退策略
- 每步剪枝/量化后必须回归评估。若精度下降超过阈值（如－1.0%），回退或调小力度。
- 统一记录：延迟（P50/P90）、峰值内存、模型大小，与教师模型对比。

产出
- 蒸馏优化后的学生模型（PyTorch/HF），为导出 ONNX/Core ML 做准备。