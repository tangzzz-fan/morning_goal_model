import argparse
from pathlib import Path
import random
import pandas as pd
from sklearn.model_selection import train_test_split

CATS = [
    "å·¥ä½œ",
    "å¥åº·",
    "å®¶åº­",
    "ä¸ªäººå‘å±•",
    "ç†è´¢",
    "ç¤¾äº¤",
    "å®¶åŠ¡",
    "å­¦ä¹ ",
    "ç¡çœ ",
    "é¥®é£Ÿ",
    "å¿ƒæ€",
    "å¨±ä¹",
    "å‡ºè¡Œ",
    "èŒä¸šå‘å±•",
    "æ²Ÿé€š",
    "è‚²å„¿",
]

PHRASES = {
    "å·¥ä½œ": [
        "å®Œæˆé¡¹ç›®è¿›åº¦æ±‡æŠ¥",
        "æ•´ç†ä¼šè®®çºªè¦",
        "æ¨è¿›éœ€æ±‚è¯„å®¡",
        "ä¼˜åŒ–æ¨¡å—ä»£ç ",
        "å¤ç›˜æ˜¨å¤©ä»»åŠ¡",
        "å‡†å¤‡PPTæ¼”ç¤º",
        "æ’°å†™å‘¨æŠ¥",
        "æ›´æ–°OKRè¿›åº¦",
        "å®‰æ’ä¸€å¯¹ä¸€æ²Ÿé€š",
        "æ¸…ç†é‚®ç®±",
        "å®Œå–„æ¥å£æ–‡æ¡£",
        "æäº¤ä»£ç Review",
        "æ­å»ºæµ‹è¯•ç”¨ä¾‹",
        "è§„åˆ’æœ¬å‘¨ä»»åŠ¡",
    ],
    "å¥åº·": [
        "æ™¨è·‘ä¸‰å…¬é‡Œ",
        "åŠ›é‡è®­ç»ƒäºŒååˆ†é’Ÿ",
        "æ—©ç¡ä¸ç†¬å¤œ",
        "é¥®æ°´ä¸¤å‡",
        "æ— ç³–é¥®é£Ÿä¸€å¤©",
        "åˆä¼‘åäº”åˆ†é’Ÿ",
        "æ‹‰ä¼¸è‚©é¢ˆ",
        "ç‘œä¼½ä¸‰ååˆ†é’Ÿ",
        "éª‘è¡Œäº”å…¬é‡Œ",
        "æ­¥è¡Œä¸€ä¸‡æ­¥",
        "å‡å°‘å’–å•¡å› ",
        "å¤šåƒè”¬æœ",
    ],
    "å®¶åº­": [
        "ä¸çˆ¶æ¯é€šè¯",
        "é™ªå­©å­é˜…è¯»",
        "æ•´ç†å®¢å…",
        "å‡†å¤‡å®¶åº­æ™šé¤",
        "ä¿®ç†ä¹¦æ¶",
        "å®‰æ’å‘¨æœ«å‡ºæ¸¸",
        "æ¸…ç†å†°ç®±",
        "é‡‡è´­æ—¥ç”¨å“",
        "æ´—è¡£ä¸æ”¶çº³",
        "å®¶åº­é¢„ç®—è®°å½•",
    ],
    "ä¸ªäººå‘å±•": [
        "é˜…è¯»ä¸‰åé¡µ",
        "è‹±è¯­å£è¯­ç»ƒä¹ ",
        "å®Œæˆä¸€èŠ‚è¯¾ç¨‹",
        "å†™ä½œäº”ç™¾å­—",
        "å†¥æƒ³ååˆ†é’Ÿ",
        "å¤ç›˜å¹´åº¦ç›®æ ‡",
        "ç»ƒä¹ æ¼”è®²",
        "åˆ·é¢˜å››ååˆ†é’Ÿ",
        "å­¦ä¹ æ–°æŠ€èƒ½",
        "æ•´ç†å­¦ä¹ ç¬”è®°",
    ],
    "ç†è´¢": [
        "è®°è´¦åäº”åˆ†é’Ÿ",
        "å®¡æŸ¥æœ¬æœˆé¢„ç®—",
        "è¿˜æ¬¾è®¡åˆ’ç¡®è®¤",
        "å‚¨è“„ç›®æ ‡æ›´æ–°",
        "æŠ•èµ„å¤ç›˜",
        "æ•´ç†å‘ç¥¨",
    ],
    "ç¤¾äº¤": [
        "è”ç³»ä¸€ä½è€æœ‹å‹",
        "å›å¤æ¶ˆæ¯æ¸…é›¶",
        "å®‰æ’å’–å•¡èŠå¤©",
        "å‚åŠ ç¤¾åŒºæ´»åŠ¨",
        "ç¤¾äº¤åª’ä½“æ–­èˆç¦»",
        "å†™æ„Ÿè°¢ä¿¡",
    ],
    "å®¶åŠ¡": [
        "æ•´ç†æˆ¿é—´",
        "æ¸…æ´å¨æˆ¿",
        "æ´—è¡£ä¸æ”¶çº³",
        "å€’åƒåœ¾",
        "æ•´ç†ä¹¦æ¡Œ",
        "æ‹–åœ°",
    ],
    "å­¦ä¹ ": [
        "å¤ä¹ ç¬”è®°",
        "å®Œæˆä½œä¸š",
        "ç»ƒä¹ ç¼–ç¨‹",
        "èƒŒå•è¯",
        "é˜…è¯»è®ºæ–‡",
        "è¯¾å ‚æ€»ç»“",
    ],
    "ç¡çœ ": [
        "æ—©ç¡",
        "åˆä¼‘åäº”åˆ†é’Ÿ",
        "ç¡å‰ä¸çœ‹æ‰‹æœº",
        "å›ºå®šä½œæ¯",
        "ç¡çœ è¿½è¸ª",
        "å‘¼å¸æ”¾æ¾",
    ],
    "é¥®é£Ÿ": [
        "å¥åº·æ—©é¤",
        "å¤‡é¤",
        "å¤šåƒè”¬æœ",
        "å‡å°‘å¤–å–",
        "æ— ç³–ä¸€å¤©",
        "å–æ°´ä¸¤å‡",
    ],
    "å¿ƒæ€": [
        "æ„Ÿæ©è®°å½•",
        "æ­£å¿µå†¥æƒ³",
        "æƒ…ç»ªå¤ç›˜",
        "ç§¯æè‚¯å®š",
        "å‘¼å¸ç»ƒä¹ ",
        "å†™æ—¥è®°",
    ],
    "å¨±ä¹": [
        "çœ‹ç”µå½±",
        "å¼¹å‰ä»–",
        "ç»˜ç”»ç»ƒä¹ ",
        "æ‘„å½±ç»ƒä¹ ",
        "å¬éŸ³ä¹",
        "æ¸¸æˆæ—¶é—´æ§åˆ¶",
    ],
    "å‡ºè¡Œ": [
        "éª‘è¡Œäº”å…¬é‡Œ",
        "æ•£æ­¥ä¸‰ååˆ†é’Ÿ",
        "å‡ºè¡Œè§„åˆ’",
        "è®¢ç¥¨",
        "è¡Œææ•´ç†",
        "é€šå‹¤æ­¥è¡Œ",
    ],
    "èŒä¸šå‘å±•": [
        "æ›´æ–°ç®€å†",
        "ä¼˜åŒ–LinkedIn",
        "ç»ƒä¹ é¢è¯•",
        "èŒä¸šè§„åˆ’",
        "å­¦ä¹ è¡Œä¸šæŠ¥å‘Š",
        "æ‹“å±•äººè„‰",
    ],
    "æ²Ÿé€š": [
        "ç»™åŒäº‹åé¦ˆ",
        "ä¸€å¯¹ä¸€ä¼šè°ˆ",
        "æ¼”è®²ç»ƒä¹ ",
        "é‚®ä»¶æ¸…é›¶",
        "å†™ä¼šè®®çºªè¦",
        "å‡†å¤‡å‘è¨€",
    ],
    "è‚²å„¿": [
        "é™ªå­©å­ç©è€",
        "å®¶åº­é˜…è¯»",
        "è¯¾åè¾…å¯¼",
        "äº²å­è¿åŠ¨",
        "æ—©ç¡å®‰æ’",
        "ç»ƒä¹ æ‹¼å›¾",
    ],
}

TEMPLATES = [
    "ä»Šå¤©çš„ç›®æ ‡ï¼š{p}",
    "ä¸“æ³¨å®Œæˆï¼š{p}",
    "åªåšä¸€ä»¶äº‹ï¼š{p}",
    "å½“æ—¥ç„¦ç‚¹ï¼š{p}",
    "ä¼˜å…ˆäº‹é¡¹ï¼š{p}",
    "Focus: {p}",
    "Just one thing: {p}",
    "è®¡åˆ’ï¼š{p}",
    "æ‰“å¡ï¼š{p}",
]

EMOJIS = [
    "ğŸ’ª",
    "ğŸ˜Š",
    "âœ…",
    "ğŸ”¥",
    "ğŸƒ",
    "ğŸ“š",
    "ğŸ§˜",
    "ğŸ",
    "â˜•",
    "ğŸ“ˆ",
]

EN_TOKENS = [
    "focus",
    "workout",
    "study",
    "meeting",
    "review",
    "plan",
]

HASH_TAGS = [
    "#å¥èº«",
    "#work",
    "#study",
    "#family",
    "#reading",
]


def apply_noise(text: str, noise_rate: float, emoji_rate: float) -> str:
    t = text
    if random.random() < noise_rate:
        t = t + random.choice(["ï¼", "ï½", "â€¦", "ã€‚", "??", "?!"])
    if random.random() < noise_rate:
        t = t + " " + random.choice(EN_TOKENS)
    if random.random() < noise_rate:
        t = t + " " + random.choice(HASH_TAGS)
    if random.random() < noise_rate:
        t = t.replace(" ", "  ")
    if random.random() < noise_rate:
        if len(t) > 3:
            i = random.randint(0, len(t) - 2)
            t = t[:i] + t[i] + t[i:]
    if random.random() < emoji_rate:
        t = t + random.choice(EMOJIS)
    return t


def gen_samples(
    count: int,
    seed: int,
    noise_rate: float,
    emoji_rate: float,
    freeform_rate: float,
) -> pd.DataFrame:
    random.seed(seed)
    rows = []
    for _ in range(count):
        cat = random.choice(CATS)
        phrase = random.choice(PHRASES[cat])
        use_template = random.random() >= freeform_rate
        if use_template:
            base = random.choice(TEMPLATES).format(p=phrase)
        else:
            base = phrase
        text = apply_noise(base, noise_rate, emoji_rate)
        label = CATS.index(cat)
        rows.append({"text": text, "label": label})
    return pd.DataFrame(rows)


def split_and_save(df: pd.DataFrame, out_dir: Path, seed: int) -> None:
    y = df["label"]
    train, tmp, y_train, y_tmp = train_test_split(
        df, y, test_size=0.3, stratify=y, random_state=seed
    )
    val, test, _, _ = train_test_split(
        tmp, y_tmp, test_size=1 / 3, stratify=y_tmp, random_state=seed
    )
    out_dir.mkdir(parents=True, exist_ok=True)
    train.to_csv(out_dir / "train.csv", index=False)
    val.to_csv(out_dir / "val.csv", index=False)
    test.to_csv(out_dir / "test.csv", index=False)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--count", type=int, default=30000)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--output_dir", default="data/processed")
    parser.add_argument("--noise_rate", type=float, default=0.3)
    parser.add_argument("--emoji_rate", type=float, default=0.25)
    parser.add_argument("--freeform_rate", type=float, default=0.4)
    args = parser.parse_args()
    df = gen_samples(
        args.count,
        args.seed,
        args.noise_rate,
        args.emoji_rate,
        args.freeform_rate,
    )
    split_and_save(df, Path(args.output_dir), args.seed)


if __name__ == "__main__":
    main()
