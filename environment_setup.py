#!/usr/bin/env python3
"""
ç¯å¢ƒé…ç½®éªŒè¯è„šæœ¬
ç”¨äºéªŒè¯Pythonç¯å¢ƒã€PyTorch/TensorFlowã€CoreMLå·¥å…·é“¾æ˜¯å¦æ­£ç¡®å®‰è£…
"""

import sys
import subprocess
import importlib
from typing import Dict, List, Tuple

def check_python_version() -> bool:
    """æ£€æŸ¥Pythonç‰ˆæœ¬æ˜¯å¦æ»¡è¶³è¦æ±‚ï¼ˆ3.8+ï¼‰"""
    version = sys.version_info
    if version.major >= 3 and version.minor >= 8:
        print(f"âœ… Pythonç‰ˆæœ¬æ£€æŸ¥é€šè¿‡: {version.major}.{version.minor}.{version.micro}")
        return True
    else:
        print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {version.major}.{version.minor}.{version.micro}ï¼Œéœ€è¦3.8+")
        return False

def check_package(package_name: str, min_version: str = None) -> Tuple[bool, str]:
    """æ£€æŸ¥åŒ…æ˜¯å¦å®‰è£…åŠç‰ˆæœ¬"""
    try:
        module = importlib.import_module(package_name)
        version = getattr(module, "__version__", "unknown")
        
        if min_version and version != "unknown":
            from packaging import version as v
            if v.parse(version) >= v.parse(min_version):
                return True, f"âœ… {package_name} {version} (>= {min_version})"
            else:
                return False, f"âŒ {package_name} {version} (< {min_version})"
        
        return True, f"âœ… {package_name} {version}"
    except ImportError:
        return False, f"âŒ {package_name} æœªå®‰è£…"

def check_gpu_support() -> Dict[str, bool]:
    """æ£€æŸ¥GPUæ”¯æŒæƒ…å†µ"""
    results = {}
    
    # PyTorch GPUæ”¯æŒ
    try:
        import torch
        results["pytorch_gpu"] = torch.cuda.is_available()
        if results["pytorch_gpu"]:
            print(f"âœ… PyTorch GPUæ”¯æŒ: {torch.cuda.get_device_name(0)}")
        else:
            print("âš ï¸ PyTorch GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    except ImportError:
        results["pytorch_gpu"] = False
        print("âŒ PyTorchæœªå®‰è£…")
    
    # TensorFlow GPUæ”¯æŒ
    try:
        import tensorflow as tf
        results["tensorflow_gpu"] = len(tf.config.list_physical_devices('GPU')) > 0
        if results["tensorflow_gpu"]:
            print(f"âœ… TensorFlow GPUæ”¯æŒ: {tf.config.list_physical_devices('GPU')}")
        else:
            print("âš ï¸ TensorFlow GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    except ImportError:
        results["tensorflow_gpu"] = False
        print("âŒ TensorFlowæœªå®‰è£…")
    
    return results

def check_coreml_tools() -> bool:
    """æ£€æŸ¥CoreMLå·¥å…·é“¾"""
    try:
        import coremltools
        version = coremltools.__version__
        print(f"âœ… CoreML Tools {version}")
        
        # æ£€æŸ¥ONNXæ”¯æŒ
        try:
            import onnx
            print(f"âœ… ONNX {onnx.__version__}")
        except ImportError:
            print("âŒ ONNXæœªå®‰è£…")
            return False
            
        return True
    except ImportError:
        print("âŒ CoreML Toolsæœªå®‰è£…")
        return False

def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œæ‰€æœ‰ç¯å¢ƒæ£€æŸ¥"""
    print("=" * 60)
    print("iOSç›®æ ‡è®°å½•åº”ç”¨ - ç«¯ä¾§NLPåˆ†æç¯å¢ƒé…ç½®éªŒè¯")
    print("=" * 60)
    
    # 1. Pythonç‰ˆæœ¬æ£€æŸ¥
    python_ok = check_python_version()
    
    # 2. æ ¸å¿ƒåŒ…æ£€æŸ¥
    required_packages = [
        ("torch", "2.0.0"),
        ("transformers", "4.30.0"),
        ("datasets", "2.0.0"),
        ("numpy", "1.21.0"),
        ("pandas", "1.3.0"),
        ("scikit-learn", "1.0.0"),
        ("matplotlib", "3.5.0"),
        ("seaborn", "0.11.0"),
        ("tqdm", "4.60.0")
    ]
    
    ml_packages = [
        ("coremltools", "5.0"),
        ("onnx", "1.12"),
        ("onnxruntime", "1.12")
    ]
    
    print("\nğŸ“¦ æ ¸å¿ƒåŒ…æ£€æŸ¥:")
    core_ok = True
    for package, min_version in required_packages:
        ok, msg = check_package(package, min_version)
        print(f"  {msg}")
        if not ok:
            core_ok = False
    
    print("\nğŸ”§ MLå·¥å…·é“¾æ£€æŸ¥:")
    ml_ok = True
    for package, min_version in ml_packages:
        ok, msg = check_package(package, min_version)
        print(f"  {msg}")
        if not ok:
            ml_ok = False
    
    # 3. GPUæ”¯æŒæ£€æŸ¥
    print("\nğŸ® GPUæ”¯æŒæ£€æŸ¥:")
    gpu_results = check_gpu_support()
    
    # 4. CoreMLå·¥å…·é“¾æ£€æŸ¥
    print("\nğŸ CoreMLå·¥å…·é“¾æ£€æŸ¥:")
    coreml_ok = check_coreml_tools()
    
    # 5. æ€»ç»“
    print("\nğŸ“‹ ç¯å¢ƒé…ç½®æ€»ç»“:")
    print("=" * 60)
    
    all_ok = python_ok and core_ok and ml_ok and coreml_ok
    
    if all_ok:
        print("âœ… ç¯å¢ƒé…ç½®æˆåŠŸï¼å¯ä»¥å¼€å§‹iOSç«¯ä¾§NLPåˆ†æå¼€å‘")
        print("\nä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. å‡†å¤‡è®­ç»ƒæ•°æ®é›†")
        print("2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹")
        print("3. å¼€å§‹æ¨¡å‹è®­ç»ƒä¸ä¼˜åŒ–")
    else:
        print("âŒ ç¯å¢ƒé…ç½®å­˜åœ¨é—®é¢˜ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºä¿®å¤")
        if not python_ok:
            print("  - å‡çº§Pythonåˆ°3.8+")
        if not core_ok:
            print("  - å®‰è£…ç¼ºå¤±çš„æ ¸å¿ƒåŒ…")
        if not ml_ok:
            print("  - å®‰è£…ç¼ºå¤±çš„MLå·¥å…·é“¾")
        if not coreml_ok:
            print("  - å®‰è£…æˆ–æ›´æ–°CoreMLå·¥å…·é“¾")
    
    # 6. ç”Ÿæˆç¯å¢ƒæŠ¥å‘Š
    print("\nğŸ“„ ç”Ÿæˆç¯å¢ƒæŠ¥å‘Š...")
    report = {
        "python_version": sys.version,
        "platform": sys.platform,
        "packages": {},
        "gpu_support": gpu_results,
        "coreml_tools": coreml_ok,
        "overall_status": all_ok
    }
    
    # è·å–æ‰€æœ‰åŒ…ç‰ˆæœ¬
    all_packages = required_packages + ml_packages
    for package, _ in all_packages:
        try:
            module = importlib.import_module(package)
            version = getattr(module, "__version__", "unknown")
            report["packages"][package] = version
        except:
            report["packages"][package] = "not_installed"
    
    # ä¿å­˜æŠ¥å‘Š
    import json
    with open("environment_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ç¯å¢ƒæŠ¥å‘Šå·²ä¿å­˜è‡³: environment_report.json")
    
    return all_ok

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)